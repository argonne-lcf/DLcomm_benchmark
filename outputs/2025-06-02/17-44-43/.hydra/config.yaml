framework: pytorch2
collective:
  name: allreduce
  op: sum
  algo: ring
buffer_size: 1MB
dtype: float32
ccl_backend: xccl
horizontal:
  num_gpus: 12
  gpu_ids:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
vertical:
  num_nodes: 12
  gpu_ids:
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
use_unitrace: true
