framework        : pytorch
ccl_backend      : nccl
extended_logging : off
barrier          : on
device_type      : gpu
memory_source    : host

order_of_run: [allreduce-across, allgather-across, reducescatter-across, broadcast-across, reduce-across, alltoall-across, alltoallsingle-across, gather-across, scatter-across, barrier-across]

allreduce-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: allreduce
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

allgather-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: allgather
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

reducescatter-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: reducescatter
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

broadcast-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: broadcast
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

reduce-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: reduce
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

alltoall-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: alltoall
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

alltoallsingle-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: alltoallsingle
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

gather-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: gather
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

scatter-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: scatter
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB

barrier-across:
  comm_group: across_node
  num_compute_nodes: 2
  num_devices_per_node: 4
  device_ids_per_node: [0,1,2,3]
  verify_correctness: on
  collective:
    collective_name: barrier
    collective_op: sum
    scale_up_algorithm: default
    scale_out_algorithm: default
    iterations: 10
    warmup_iterations: 0
    add_mxm_compute: on
    payload:
      dtype: float32
      count: 
      buffer_size: 1GB
