[2025-08-06 20:05:08,088][DL_COMM][INFO] - -------------------------------------------------------------------------
[2025-08-06 20:05:08,090][DL_COMM][INFO] - [CONFIG] Loading schema and validating user YAML
[2025-08-06 20:05:08,090][DL_COMM][INFO] - [DEBUG] Current working directory: /lus/eagle/projects/datascience_collab/mcim/workspace/DLcomm_benchmark/examples
[2025-08-06 20:05:08,090][DL_COMM][INFO] - [DEBUG] Script location: /lus/eagle/projects/datascience_collab/mcim/workspace/DLcomm_benchmark/dl_comm
[2025-08-06 20:05:08,090][DL_COMM][INFO] - [DEBUG] Implementations to run: ['allreduce-scale', 'allgather-scale', 'reducescatter-scale', 'broadcast-scale', 'reduce-scale', 'alltoall-scale', 'alltoallsingle-scale', 'gather-scale', 'scatter-scale', 'barrier-scale']
[2025-08-06 20:05:08,090][DL_COMM][INFO] - [DEBUG] Config loaded successfully
[2025-08-06 20:05:08,090][DL_COMM][INFO] - 
[2025-08-06 20:05:08,090][DL_COMM][INFO] - [SYSTEM] Collecting environment information...
[2025-08-06 20:05:08,090][DL_COMM][INFO] - [SYSTEM] ======================================================
[2025-08-06 20:05:08,091][DL_COMM][INFO] - [SYSTEM] PyTorch version: 2.3.0
[2025-08-06 20:05:09,518][DL_COMM][INFO] - [SYSTEM] CUDA used to build PyTorch: 12.4
[2025-08-06 20:05:09,518][DL_COMM][INFO] - 
[2025-08-06 20:05:09,524][DL_COMM][INFO] - [SYSTEM] OS: Linux-5.14.21-150500.55.49-default-x86_64-with-glibc2.31
[2025-08-06 20:05:09,529][DL_COMM][INFO] - [SYSTEM] GCC version: gcc (SUSE Linux) 7.5.0
[2025-08-06 20:05:09,529][DL_COMM][INFO] - 
[2025-08-06 20:05:09,529][DL_COMM][INFO] - [SYSTEM] Python version: 3.11.8 | packaged by conda-forge | (main, Feb 16 2024, 20:53:32) [GCC 12.3.0]
[2025-08-06 20:05:09,529][DL_COMM][INFO] - [SYSTEM] Python platform: Linux-5.14.21-150500.55.49-default-x86_64-with-glibc2.31
[2025-08-06 20:05:09,530][DL_COMM][INFO] - [SYSTEM] Is CUDA available: True
[2025-08-06 20:05:09,530][DL_COMM][INFO] - [SYSTEM] CUDA runtime version: 12.4
[2025-08-06 20:05:09,530][DL_COMM][INFO] - [SYSTEM] GPU models and configuration:
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] GPU 0: NVIDIA A100-SXM4-40GB (39.4 GB)
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] GPU 1: NVIDIA A100-SXM4-40GB (39.4 GB)
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] GPU 2: NVIDIA A100-SXM4-40GB (39.4 GB)
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] GPU 3: NVIDIA A100-SXM4-40GB (39.4 GB)
[2025-08-06 20:05:09,593][DL_COMM][INFO] - 
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] Distributed Backend Availability:
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] NCCL backend available: True
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] MPI backend available: True
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] XCCL backend available: Unknown (API not available)
[2025-08-06 20:05:09,593][DL_COMM][INFO] - 
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] Versions of relevant libraries:
[2025-08-06 20:05:09,593][DL_COMM][INFO] - [SYSTEM] numpy: 1.26.4
[2025-08-06 20:05:09,594][DL_COMM][INFO] - [SYSTEM] mpi4py: 3.1.6
[2025-08-06 20:05:09,594][DL_COMM][INFO] - [SYSTEM] hydra-core: 1.3.2
[2025-08-06 20:05:09,594][DL_COMM][INFO] - [SYSTEM] omegaconf: 2.3.0
[2025-08-06 20:05:09,594][DL_COMM][INFO] - [SYSTEM] oneccl_bindings_for_pytorch: Not available
[2025-08-06 20:05:09,594][DL_COMM][INFO] - [SYSTEM] intel_extension_for_pytorch: Not available
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] NCCL version: 2.20.5
[2025-08-06 20:05:09,595][DL_COMM][INFO] - 
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] Relevant Environment Variables:
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_ATL_SHM                    = 1
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_ATL_TRANSPORT              = ofi
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_ENABLE_AUTO_CACHE          = 1
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_ENABLE_PROFILING           = 1
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_KVS_CONNECTION_TIMEOUT     = 600
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_KVS_MODE                   = mpi
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_LOG_LEVEL                  = info
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_OP_SYNC                    = 1
[2025-08-06 20:05:09,595][DL_COMM][INFO] - [SYSTEM] CCL_PROCESS_LAUNCHER           = pmix
[2025-08-06 20:05:09,596][DL_COMM][INFO] - [SYSTEM] CUDA_HOME                      = /soft/compilers/cudatoolkit/cuda-12.4.1/
[2025-08-06 20:05:09,596][DL_COMM][INFO] - [SYSTEM] CUDA_MODULE_LOADING            = LAZY
[2025-08-06 20:05:09,596][DL_COMM][INFO] - [SYSTEM] CUDA_PATH                      = /soft/compilers/cudatoolkit/cuda-12.4.1/
[2025-08-06 20:05:09,596][DL_COMM][INFO] - [SYSTEM] CUDA_TOOLKIT_BASE              = /soft/compilers/cudatoolkit/cuda-12.4.1/
[2025-08-06 20:05:09,596][DL_COMM][INFO] - [SYSTEM] MPI4JAX_USE_CUDA_MPI           = 1
[2025-08-06 20:05:09,596][DL_COMM][INFO] - [SYSTEM] TORCH_CUDA_ARCH_LIST           = 8.0
[2025-08-06 20:05:09,596][DL_COMM][INFO] - [SYSTEM] ======================================================
[2025-08-06 20:05:09,596][DL_COMM][INFO] - 
[2025-08-06 20:05:09,618][DL_COMM][INFO] - 
[2025-08-06 20:05:09,618][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,618][DL_COMM][INFO] - [IMPLEMENTATION 1/10] ==================== ALLREDUCE-SCALE ====================
[2025-08-06 20:05:09,618][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,618][DL_COMM][INFO] - 
[2025-08-06 20:05:09,618][DL_COMM][INFO] - 
[2025-08-06 20:05:09,619][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,619][DL_COMM][INFO] - 
[2025-08-06 20:05:09,619][DL_COMM][WARNING] - [SKIP] allreduce-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,619][DL_COMM][INFO] - 
[2025-08-06 20:05:09,619][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,619][DL_COMM][INFO] - [IMPLEMENTATION 2/10] ==================== ALLGATHER-SCALE ====================
[2025-08-06 20:05:09,619][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,619][DL_COMM][INFO] - 
[2025-08-06 20:05:09,619][DL_COMM][INFO] - 
[2025-08-06 20:05:09,619][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,620][DL_COMM][INFO] - 
[2025-08-06 20:05:09,620][DL_COMM][WARNING] - [SKIP] allgather-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,620][DL_COMM][INFO] - 
[2025-08-06 20:05:09,620][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,620][DL_COMM][INFO] - [IMPLEMENTATION 3/10] ==================== REDUCESCATTER-SCALE ====================
[2025-08-06 20:05:09,620][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,620][DL_COMM][INFO] - 
[2025-08-06 20:05:09,620][DL_COMM][INFO] - 
[2025-08-06 20:05:09,620][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,621][DL_COMM][INFO] - 
[2025-08-06 20:05:09,621][DL_COMM][WARNING] - [SKIP] reducescatter-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,621][DL_COMM][INFO] - 
[2025-08-06 20:05:09,621][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,621][DL_COMM][INFO] - [IMPLEMENTATION 4/10] ==================== BROADCAST-SCALE ====================
[2025-08-06 20:05:09,621][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,621][DL_COMM][INFO] - 
[2025-08-06 20:05:09,621][DL_COMM][INFO] - 
[2025-08-06 20:05:09,621][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,622][DL_COMM][INFO] - 
[2025-08-06 20:05:09,622][DL_COMM][WARNING] - [SKIP] broadcast-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,622][DL_COMM][INFO] - 
[2025-08-06 20:05:09,622][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,622][DL_COMM][INFO] - [IMPLEMENTATION 5/10] ==================== REDUCE-SCALE ====================
[2025-08-06 20:05:09,622][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,622][DL_COMM][INFO] - 
[2025-08-06 20:05:09,622][DL_COMM][INFO] - 
[2025-08-06 20:05:09,623][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,623][DL_COMM][INFO] - 
[2025-08-06 20:05:09,623][DL_COMM][WARNING] - [SKIP] reduce-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,623][DL_COMM][INFO] - 
[2025-08-06 20:05:09,623][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,623][DL_COMM][INFO] - [IMPLEMENTATION 6/10] ==================== ALLTOALL-SCALE ====================
[2025-08-06 20:05:09,623][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,623][DL_COMM][INFO] - 
[2025-08-06 20:05:09,624][DL_COMM][INFO] - 
[2025-08-06 20:05:09,624][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,624][DL_COMM][INFO] - 
[2025-08-06 20:05:09,624][DL_COMM][WARNING] - [SKIP] alltoall-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,624][DL_COMM][INFO] - 
[2025-08-06 20:05:09,624][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,624][DL_COMM][INFO] - [IMPLEMENTATION 7/10] ==================== ALLTOALLSINGLE-SCALE ====================
[2025-08-06 20:05:09,624][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,624][DL_COMM][INFO] - 
[2025-08-06 20:05:09,625][DL_COMM][INFO] - 
[2025-08-06 20:05:09,625][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,625][DL_COMM][INFO] - 
[2025-08-06 20:05:09,625][DL_COMM][WARNING] - [SKIP] alltoallsingle-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,625][DL_COMM][INFO] - 
[2025-08-06 20:05:09,625][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,625][DL_COMM][INFO] - [IMPLEMENTATION 8/10] ==================== GATHER-SCALE ====================
[2025-08-06 20:05:09,625][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,625][DL_COMM][INFO] - 
[2025-08-06 20:05:09,626][DL_COMM][INFO] - 
[2025-08-06 20:05:09,626][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,626][DL_COMM][INFO] - 
[2025-08-06 20:05:09,626][DL_COMM][WARNING] - [SKIP] gather-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,626][DL_COMM][INFO] - 
[2025-08-06 20:05:09,626][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,626][DL_COMM][INFO] - [IMPLEMENTATION 9/10] ==================== SCATTER-SCALE ====================
[2025-08-06 20:05:09,626][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,626][DL_COMM][INFO] - 
[2025-08-06 20:05:09,627][DL_COMM][INFO] - 
[2025-08-06 20:05:09,627][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,627][DL_COMM][INFO] - 
[2025-08-06 20:05:09,627][DL_COMM][WARNING] - [SKIP] scatter-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,627][DL_COMM][INFO] - 
[2025-08-06 20:05:09,627][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,627][DL_COMM][INFO] - [IMPLEMENTATION 10/10] ==================== BARRIER-SCALE ====================
[2025-08-06 20:05:09,627][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,627][DL_COMM][INFO] - 
[2025-08-06 20:05:09,628][DL_COMM][INFO] - 
[2025-08-06 20:05:09,628][DL_COMM][INFO] - [MODE 1/1] ---------- ACROSS_NODE ----------
[2025-08-06 20:05:09,628][DL_COMM][INFO] - 
[2025-08-06 20:05:09,628][DL_COMM][WARNING] - [SKIP] barrier-scale_across_node requires 1800 ranks but only 4 available - skipping
[2025-08-06 20:05:09,628][DL_COMM][INFO] - 
[2025-08-06 20:05:09,628][DL_COMM][INFO] - ================================================================================
[2025-08-06 20:05:09,628][DL_COMM][INFO] - [FINAL] All 10 implementations completed successfully!
[2025-08-06 20:05:09,628][DL_COMM][INFO] - ================================================================================
